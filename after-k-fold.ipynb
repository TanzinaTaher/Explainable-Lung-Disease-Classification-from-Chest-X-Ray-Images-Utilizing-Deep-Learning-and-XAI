{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.applications import Xception\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import StratifiedKFold\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom sklearn.metrics import classification_report, confusion_matrix","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-07T09:55:49.610543Z","iopub.execute_input":"2023-11-07T09:55:49.611420Z","iopub.status.idle":"2023-11-07T09:55:58.073023Z","shell.execute_reply.started":"2023-11-07T09:55:49.611382Z","shell.execute_reply":"2023-11-07T09:55:58.072218Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"image_path = '/kaggle/input/k-fold-images/images'","metadata":{"execution":{"iopub.status.busy":"2023-11-07T09:55:58.074851Z","iopub.execute_input":"2023-11-07T09:55:58.075396Z","iopub.status.idle":"2023-11-07T09:55:58.079604Z","shell.execute_reply.started":"2023-11-07T09:55:58.075369Z","shell.execute_reply":"2023-11-07T09:55:58.078776Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"input_shape = (299, 299) \nbatch_size = 32\nnum_epochs = 31\nnum_folds = 4 ","metadata":{"execution":{"iopub.status.busy":"2023-11-07T09:55:58.080806Z","iopub.execute_input":"2023-11-07T09:55:58.081151Z","iopub.status.idle":"2023-11-07T09:55:58.092092Z","shell.execute_reply.started":"2023-11-07T09:55:58.081118Z","shell.execute_reply":"2023-11-07T09:55:58.091230Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data_gen = ImageDataGenerator(\n                    rescale=1./255,\n                    width_shift_range=0.2,\n                    height_shift_range=0.2,\n                    zoom_range=0.2,\n                    horizontal_flip=True,\n                    vertical_flip=False,\n                    rotation_range=10,  \n                    shear_range=0.2,\n                    brightness_range=[0.8, 1.2])","metadata":{"execution":{"iopub.status.busy":"2023-11-07T09:55:58.093139Z","iopub.execute_input":"2023-11-07T09:55:58.093547Z","iopub.status.idle":"2023-11-07T09:55:58.104055Z","shell.execute_reply.started":"2023-11-07T09:55:58.093511Z","shell.execute_reply":"2023-11-07T09:55:58.103302Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"classes = os.listdir(image_path)\n\nall_image_paths = []\nall_labels = []\n\nfor class_name in classes:\n    class_path = os.path.join(image_path, class_name)\n    class_images = os.listdir(class_path)\n    class_image_paths = [os.path.join(class_path, image) for image in class_images]\n    all_image_paths.extend(class_image_paths)\n    all_labels.extend([class_name] * len(class_image_paths))\n\nall_image_paths = np.array(all_image_paths)\nall_labels = np.array(all_labels)\n\nstratified_kfold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-11-07T09:55:58.106146Z","iopub.execute_input":"2023-11-07T09:55:58.106441Z","iopub.status.idle":"2023-11-07T09:56:00.028624Z","shell.execute_reply.started":"2023-11-07T09:55:58.106416Z","shell.execute_reply":"2023-11-07T09:56:00.027846Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"len(classes)","metadata":{"execution":{"iopub.status.busy":"2023-11-07T09:56:00.029612Z","iopub.execute_input":"2023-11-07T09:56:00.029897Z","iopub.status.idle":"2023-11-07T09:56:00.036758Z","shell.execute_reply.started":"2023-11-07T09:56:00.029872Z","shell.execute_reply":"2023-11-07T09:56:00.035870Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"5"},"metadata":{}}]},{"cell_type":"code","source":"base_model = Xception(weights='imagenet', include_top=False, input_shape=(*input_shape, 3))\nmodel = Sequential([\n    base_model,\n    GlobalAveragePooling2D(),\n    Dense(256, activation='relu'),\n    Dense(len(classes), activation='softmax')\n])\n","metadata":{"execution":{"iopub.status.busy":"2023-11-07T09:56:00.037898Z","iopub.execute_input":"2023-11-07T09:56:00.038199Z","iopub.status.idle":"2023-11-07T09:56:05.562924Z","shell.execute_reply.started":"2023-11-07T09:56:00.038175Z","shell.execute_reply":"2023-11-07T09:56:05.562178Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n83683744/83683744 [==============================] - 0s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-11-07T09:56:05.564000Z","iopub.execute_input":"2023-11-07T09:56:05.564284Z","iopub.status.idle":"2023-11-07T09:56:05.583543Z","shell.execute_reply.started":"2023-11-07T09:56:05.564260Z","shell.execute_reply":"2023-11-07T09:56:05.582767Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"for fold, (train_indices, val_indices) in enumerate(stratified_kfold.split(all_image_paths, all_labels)):\n    train_data = all_image_paths[train_indices]\n    train_labels = all_labels[train_indices]\n    val_data = all_image_paths[val_indices]\n    val_labels = all_labels[val_indices]\n    print(\"################# Results for fold:-\", fold+1, \"###################\")\n    train_generator = data_gen.flow_from_dataframe(\n        dataframe=pd.DataFrame({'filepath': train_data, 'class': train_labels}),\n        x_col='filepath',\n        y_col='class',\n        target_size=input_shape,\n        batch_size=batch_size,\n        class_mode='categorical',\n        shuffle=True,\n    )\n\n    val_generator = data_gen.flow_from_dataframe(\n        dataframe=pd.DataFrame({'filepath': val_data, 'class': val_labels}),\n        x_col='filepath',\n        y_col='class',\n        target_size=input_shape,\n        batch_size=batch_size,\n        class_mode='categorical',\n        shuffle=False,\n    )\n    \n\n    Checkpoint = ModelCheckpoint(\"K-Xception.hdf5\", monitor=\"val_accuracy\", save_best_only=True, mode=\"max\")\n    model.fit(\n        train_generator,\n        epochs=num_epochs,\n        validation_data=val_generator,\n        callbacks=[Checkpoint]\n    )\n    \n    new_model=tf.keras.models.load_model(\"/kaggle/working/K-Xception.hdf5\")\n    \n    predictions = new_model.predict(val_generator)\n    predicted_labels = np.argmax(predictions, axis=1)\n    true_labels = val_generator.classes\n\n    class_names = list(val_generator.class_indices.keys())\n    report = classification_report(true_labels, predicted_labels, target_names=class_names)\n    \n    print(f\"Fold {fold + 1}:\")\n    print(\"Classification Report:\")\n    print(report)\n\n    # Calculate and display the confusion matrix\n    confusion_mat = confusion_matrix(true_labels, predicted_labels)\n    print(\"Confusion Matrix:\")\n    print(confusion_mat)\n\nmodel.save('xception_model.h5')\n","metadata":{"execution":{"iopub.status.busy":"2023-11-07T09:56:05.584847Z","iopub.execute_input":"2023-11-07T09:56:05.585133Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"################# Results for fold:- 1 ###################\nFound 8076 validated image filenames belonging to 5 classes.\nFound 2019 validated image filenames belonging to 5 classes.\nEpoch 1/31\n253/253 [==============================] - 426s 2s/step - loss: 0.5307 - accuracy: 0.7995 - val_loss: 0.7086 - val_accuracy: 0.7984\nEpoch 2/31\n253/253 [==============================] - 305s 1s/step - loss: 0.3813 - accuracy: 0.8519 - val_loss: 1.8229 - val_accuracy: 0.6632\nEpoch 3/31\n253/253 [==============================] - 305s 1s/step - loss: 0.3303 - accuracy: 0.8717 - val_loss: 0.4100 - val_accuracy: 0.8489\nEpoch 4/31\n253/253 [==============================] - 296s 1s/step - loss: 0.2885 - accuracy: 0.8836 - val_loss: 0.4910 - val_accuracy: 0.8336\nEpoch 5/31\n253/253 [==============================] - 297s 1s/step - loss: 0.3023 - accuracy: 0.8817 - val_loss: 0.3788 - val_accuracy: 0.8534\nEpoch 6/31\n253/253 [==============================] - 296s 1s/step - loss: 0.2808 - accuracy: 0.8895 - val_loss: 0.3954 - val_accuracy: 0.8430\nEpoch 7/31\n253/253 [==============================] - 295s 1s/step - loss: 0.2705 - accuracy: 0.8940 - val_loss: 0.4163 - val_accuracy: 0.8479\nEpoch 8/31\n253/253 [==============================] - 298s 1s/step - loss: 0.2483 - accuracy: 0.9016 - val_loss: 0.3089 - val_accuracy: 0.8722\nEpoch 9/31\n253/253 [==============================] - 299s 1s/step - loss: 0.2307 - accuracy: 0.9068 - val_loss: 0.3066 - val_accuracy: 0.8895\nEpoch 10/31\n253/253 [==============================] - 299s 1s/step - loss: 0.2261 - accuracy: 0.9120 - val_loss: 0.4099 - val_accuracy: 0.8534\nEpoch 11/31\n253/253 [==============================] - 292s 1s/step - loss: 0.2209 - accuracy: 0.9110 - val_loss: 0.3642 - val_accuracy: 0.8633\nEpoch 12/31\n253/253 [==============================] - 295s 1s/step - loss: 0.2182 - accuracy: 0.9131 - val_loss: 0.3404 - val_accuracy: 0.8811\nEpoch 13/31\n253/253 [==============================] - 297s 1s/step - loss: 0.2038 - accuracy: 0.9240 - val_loss: 0.2862 - val_accuracy: 0.8905\nEpoch 14/31\n253/253 [==============================] - 299s 1s/step - loss: 0.1972 - accuracy: 0.9214 - val_loss: 0.2213 - val_accuracy: 0.9064\nEpoch 15/31\n253/253 [==============================] - 300s 1s/step - loss: 0.1995 - accuracy: 0.9230 - val_loss: 1.1470 - val_accuracy: 0.7410\nEpoch 16/31\n253/253 [==============================] - 301s 1s/step - loss: 0.1834 - accuracy: 0.9315 - val_loss: 0.4874 - val_accuracy: 0.8425\nEpoch 17/31\n253/253 [==============================] - 299s 1s/step - loss: 0.1827 - accuracy: 0.9314 - val_loss: 0.4510 - val_accuracy: 0.8534\nEpoch 18/31\n253/253 [==============================] - 295s 1s/step - loss: 0.1714 - accuracy: 0.9335 - val_loss: 0.2449 - val_accuracy: 0.8980\nEpoch 19/31\n253/253 [==============================] - 293s 1s/step - loss: 0.1635 - accuracy: 0.9378 - val_loss: 0.3877 - val_accuracy: 0.8405\nEpoch 20/31\n253/253 [==============================] - 293s 1s/step - loss: 0.1696 - accuracy: 0.9378 - val_loss: 0.2622 - val_accuracy: 0.9034\nEpoch 21/31\n253/253 [==============================] - 297s 1s/step - loss: 0.1529 - accuracy: 0.9423 - val_loss: 0.3635 - val_accuracy: 0.8742\nEpoch 22/31\n253/253 [==============================] - 300s 1s/step - loss: 0.1407 - accuracy: 0.9482 - val_loss: 0.4032 - val_accuracy: 0.8405\nEpoch 23/31\n253/253 [==============================] - 298s 1s/step - loss: 0.1463 - accuracy: 0.9412 - val_loss: 0.3476 - val_accuracy: 0.8603\nEpoch 24/31\n253/253 [==============================] - 292s 1s/step - loss: 0.1320 - accuracy: 0.9508 - val_loss: 0.5495 - val_accuracy: 0.8252\nEpoch 25/31\n253/253 [==============================] - 294s 1s/step - loss: 0.1357 - accuracy: 0.9487 - val_loss: 0.6210 - val_accuracy: 0.8351\nEpoch 26/31\n253/253 [==============================] - 294s 1s/step - loss: 0.1254 - accuracy: 0.9539 - val_loss: 0.2880 - val_accuracy: 0.9099\nEpoch 27/31\n253/253 [==============================] - 298s 1s/step - loss: 0.1303 - accuracy: 0.9517 - val_loss: 0.5789 - val_accuracy: 0.8053\nEpoch 28/31\n253/253 [==============================] - 296s 1s/step - loss: 0.1116 - accuracy: 0.9583 - val_loss: 0.3321 - val_accuracy: 0.9089\nEpoch 29/31\n253/253 [==============================] - 292s 1s/step - loss: 0.1105 - accuracy: 0.9590 - val_loss: 0.2875 - val_accuracy: 0.8990\nEpoch 30/31\n253/253 [==============================] - 296s 1s/step - loss: 0.1098 - accuracy: 0.9578 - val_loss: 0.2448 - val_accuracy: 0.9089\nEpoch 31/31\n253/253 [==============================] - 296s 1s/step - loss: 0.1126 - accuracy: 0.9601 - val_loss: 0.3184 - val_accuracy: 0.9029\n64/64 [==============================] - 59s 916ms/step\nFold 1:\nClassification Report:\n                      precision    recall  f1-score   support\n\n Bacterial Pneumonia       0.84      0.79      0.81       402\nCorona Virus Disease       0.99      0.98      0.99       406\n              Normal       0.90      0.99      0.94       403\n        Tuberculosis       0.99      1.00      1.00       407\n     Viral Pneumonia       0.80      0.77      0.78       401\n\n            accuracy                           0.90      2019\n           macro avg       0.90      0.90      0.90      2019\n        weighted avg       0.90      0.90      0.90      2019\n\nConfusion Matrix:\n[[316   3  12   0  71]\n [  0 398   3   3   2]\n [  0   0 397   1   5]\n [  0   0   0 407   0]\n [ 61   0  31   0 309]]\n################# Results for fold:- 2 ###################\nFound 8076 validated image filenames belonging to 5 classes.\nFound 2019 validated image filenames belonging to 5 classes.\nEpoch 1/31\n253/253 [==============================] - 299s 1s/step - loss: 0.1285 - accuracy: 0.9526 - val_loss: 0.2396 - val_accuracy: 0.8990\nEpoch 2/31\n253/253 [==============================] - 296s 1s/step - loss: 0.1153 - accuracy: 0.9578 - val_loss: 0.2220 - val_accuracy: 0.9203\nEpoch 3/31\n253/253 [==============================] - 293s 1s/step - loss: 0.1132 - accuracy: 0.9589 - val_loss: 0.1790 - val_accuracy: 0.9292\nEpoch 4/31\n253/253 [==============================] - 295s 1s/step - loss: 0.1039 - accuracy: 0.9614 - val_loss: 0.1991 - val_accuracy: 0.9257\nEpoch 5/31\n253/253 [==============================] - 297s 1s/step - loss: 0.0978 - accuracy: 0.9650 - val_loss: 0.1833 - val_accuracy: 0.9307\nEpoch 6/31\n253/253 [==============================] - 291s 1s/step - loss: 0.0903 - accuracy: 0.9673 - val_loss: 0.5075 - val_accuracy: 0.8747\nEpoch 7/31\n253/253 [==============================] - 293s 1s/step - loss: 0.0952 - accuracy: 0.9661 - val_loss: 0.3071 - val_accuracy: 0.8821\nEpoch 8/31\n253/253 [==============================] - 287s 1s/step - loss: 0.0811 - accuracy: 0.9695 - val_loss: 0.2805 - val_accuracy: 0.9074\nEpoch 9/31\n253/253 [==============================] - 295s 1s/step - loss: 0.0813 - accuracy: 0.9697 - val_loss: 0.2146 - val_accuracy: 0.9272\nEpoch 10/31\n253/253 [==============================] - 293s 1s/step - loss: 0.0804 - accuracy: 0.9720 - val_loss: 0.1904 - val_accuracy: 0.9321\nEpoch 11/31\n253/253 [==============================] - 297s 1s/step - loss: 0.0723 - accuracy: 0.9734 - val_loss: 0.2207 - val_accuracy: 0.9302\nEpoch 12/31\n253/253 [==============================] - 294s 1s/step - loss: 0.0767 - accuracy: 0.9707 - val_loss: 0.3827 - val_accuracy: 0.8777\nEpoch 13/31\n253/253 [==============================] - 296s 1s/step - loss: 0.0688 - accuracy: 0.9751 - val_loss: 0.3430 - val_accuracy: 0.9054\nEpoch 14/31\n253/253 [==============================] - 295s 1s/step - loss: 0.0705 - accuracy: 0.9749 - val_loss: 0.2246 - val_accuracy: 0.9104\nEpoch 15/31\n253/253 [==============================] - 296s 1s/step - loss: 0.0704 - accuracy: 0.9744 - val_loss: 0.1624 - val_accuracy: 0.9425\nEpoch 16/31\n253/253 [==============================] - 296s 1s/step - loss: 0.0597 - accuracy: 0.9801 - val_loss: 0.2009 - val_accuracy: 0.9371\nEpoch 17/31\n253/253 [==============================] - 294s 1s/step - loss: 0.0595 - accuracy: 0.9787 - val_loss: 0.1957 - val_accuracy: 0.9386\nEpoch 18/31\n253/253 [==============================] - 302s 1s/step - loss: 0.0666 - accuracy: 0.9761 - val_loss: 0.4519 - val_accuracy: 0.8435\nEpoch 19/31\n253/253 [==============================] - 298s 1s/step - loss: 0.0637 - accuracy: 0.9772 - val_loss: 0.2879 - val_accuracy: 0.9158\nEpoch 20/31\n253/253 [==============================] - 301s 1s/step - loss: 0.0565 - accuracy: 0.9792 - val_loss: 0.2653 - val_accuracy: 0.9143\nEpoch 21/31\n253/253 [==============================] - 295s 1s/step - loss: 0.0630 - accuracy: 0.9771 - val_loss: 0.2412 - val_accuracy: 0.9222\nEpoch 22/31\n253/253 [==============================] - 296s 1s/step - loss: 0.0499 - accuracy: 0.9823 - val_loss: 0.7287 - val_accuracy: 0.8296\nEpoch 23/31\n253/253 [==============================] - 295s 1s/step - loss: 0.0449 - accuracy: 0.9843 - val_loss: 0.1303 - val_accuracy: 0.9559\nEpoch 24/31\n253/253 [==============================] - 294s 1s/step - loss: 0.0518 - accuracy: 0.9834 - val_loss: 0.2820 - val_accuracy: 0.9237\nEpoch 25/31\n253/253 [==============================] - 295s 1s/step - loss: 0.0474 - accuracy: 0.9832 - val_loss: 0.2664 - val_accuracy: 0.9143\nEpoch 26/31\n253/253 [==============================] - 295s 1s/step - loss: 0.0472 - accuracy: 0.9829 - val_loss: 0.1923 - val_accuracy: 0.9445\nEpoch 27/31\n253/253 [==============================] - 296s 1s/step - loss: 0.0543 - accuracy: 0.9808 - val_loss: 0.3249 - val_accuracy: 0.9079\nEpoch 28/31\n253/253 [==============================] - 294s 1s/step - loss: 0.0470 - accuracy: 0.9844 - val_loss: 0.2328 - val_accuracy: 0.9168\nEpoch 29/31\n253/253 [==============================] - 297s 1s/step - loss: 0.0520 - accuracy: 0.9835 - val_loss: 0.2061 - val_accuracy: 0.9361\nEpoch 30/31\n253/253 [==============================] - 295s 1s/step - loss: 0.0469 - accuracy: 0.9850 - val_loss: 0.2290 - val_accuracy: 0.9297\nEpoch 31/31\n253/253 [==============================] - 295s 1s/step - loss: 0.0442 - accuracy: 0.9840 - val_loss: 0.2376 - val_accuracy: 0.9287\n64/64 [==============================] - 58s 892ms/step\nFold 2:\nClassification Report:\n                      precision    recall  f1-score   support\n\n Bacterial Pneumonia       0.90      0.89      0.90       402\nCorona Virus Disease       0.99      0.99      0.99       406\n              Normal       0.97      0.98      0.97       403\n        Tuberculosis       0.99      1.00      1.00       407\n     Viral Pneumonia       0.88      0.88      0.88       401\n\n            accuracy                           0.95      2019\n           macro avg       0.95      0.95      0.95      2019\n        weighted avg       0.95      0.95      0.95      2019\n\nConfusion Matrix:\n[[357   2   2   0  41]\n [  0 403   0   3   0]\n [  1   2 393   0   7]\n [  0   0   0 407   0]\n [ 37   1  12   0 351]]\n################# Results for fold:- 3 ###################\nFound 8076 validated image filenames belonging to 5 classes.\nFound 2019 validated image filenames belonging to 5 classes.\nEpoch 1/31\n253/253 [==============================] - 298s 1s/step - loss: 0.0728 - accuracy: 0.9757 - val_loss: 0.1725 - val_accuracy: 0.9351\nEpoch 2/31\n253/253 [==============================] - 296s 1s/step - loss: 0.0602 - accuracy: 0.9794 - val_loss: 0.0792 - val_accuracy: 0.9683\nEpoch 3/31\n253/253 [==============================] - 293s 1s/step - loss: 0.0526 - accuracy: 0.9801 - val_loss: 0.1531 - val_accuracy: 0.9450\nEpoch 4/31\n253/253 [==============================] - 295s 1s/step - loss: 0.0536 - accuracy: 0.9829 - val_loss: 0.0712 - val_accuracy: 0.9757\nEpoch 5/31\n253/253 [==============================] - 297s 1s/step - loss: 0.0547 - accuracy: 0.9801 - val_loss: 0.1951 - val_accuracy: 0.9346\nEpoch 6/31\n253/253 [==============================] - 298s 1s/step - loss: 0.0489 - accuracy: 0.9842 - val_loss: 0.0940 - val_accuracy: 0.9678\nEpoch 7/31\n253/253 [==============================] - 298s 1s/step - loss: 0.0443 - accuracy: 0.9838 - val_loss: 0.0801 - val_accuracy: 0.9698\nEpoch 8/31\n253/253 [==============================] - 297s 1s/step - loss: 0.0471 - accuracy: 0.9827 - val_loss: 0.2018 - val_accuracy: 0.9401\nEpoch 9/31\n253/253 [==============================] - 295s 1s/step - loss: 0.0442 - accuracy: 0.9848 - val_loss: 0.1000 - val_accuracy: 0.9703\nEpoch 10/31\n253/253 [==============================] - 296s 1s/step - loss: 0.0444 - accuracy: 0.9856 - val_loss: 0.1193 - val_accuracy: 0.9633\nEpoch 11/31\n253/253 [==============================] - 298s 1s/step - loss: 0.0435 - accuracy: 0.9864 - val_loss: 0.1600 - val_accuracy: 0.9485\nEpoch 12/31\n253/253 [==============================] - 298s 1s/step - loss: 0.0438 - accuracy: 0.9854 - val_loss: 0.0710 - val_accuracy: 0.9742\nEpoch 13/31\n253/253 [==============================] - 302s 1s/step - loss: 0.0389 - accuracy: 0.9855 - val_loss: 0.1272 - val_accuracy: 0.9619\nEpoch 14/31\n253/253 [==============================] - 294s 1s/step - loss: 0.0494 - accuracy: 0.9830 - val_loss: 0.3092 - val_accuracy: 0.9128\nEpoch 15/31\n253/253 [==============================] - 298s 1s/step - loss: 0.0461 - accuracy: 0.9837 - val_loss: 0.3059 - val_accuracy: 0.9064\nEpoch 16/31\n253/253 [==============================] - 296s 1s/step - loss: 0.0381 - accuracy: 0.9875 - val_loss: 0.1106 - val_accuracy: 0.9638\nEpoch 17/31\n253/253 [==============================] - 298s 1s/step - loss: 0.0366 - accuracy: 0.9868 - val_loss: 0.0748 - val_accuracy: 0.9718\nEpoch 18/31\n253/253 [==============================] - 295s 1s/step - loss: 0.0252 - accuracy: 0.9921 - val_loss: 0.1075 - val_accuracy: 0.9614\nEpoch 19/31\n253/253 [==============================] - 298s 1s/step - loss: 0.0435 - accuracy: 0.9845 - val_loss: 0.1486 - val_accuracy: 0.9520\nEpoch 20/31\n253/253 [==============================] - 295s 1s/step - loss: 0.0336 - accuracy: 0.9877 - val_loss: 0.0863 - val_accuracy: 0.9708\nEpoch 21/31\n253/253 [==============================] - 298s 1s/step - loss: 0.0394 - accuracy: 0.9872 - val_loss: 0.2662 - val_accuracy: 0.9118\nEpoch 22/31\n253/253 [==============================] - 302s 1s/step - loss: 0.0381 - accuracy: 0.9861 - val_loss: 0.2390 - val_accuracy: 0.9351\nEpoch 24/31\n253/253 [==============================] - 298s 1s/step - loss: 0.0355 - accuracy: 0.9861 - val_loss: 0.1456 - val_accuracy: 0.9520\nEpoch 25/31\n253/253 [==============================] - 298s 1s/step - loss: 0.0280 - accuracy: 0.9916 - val_loss: 0.1442 - val_accuracy: 0.9529\nEpoch 26/31\n253/253 [==============================] - 295s 1s/step - loss: 0.0359 - accuracy: 0.9879 - val_loss: 0.2532 - val_accuracy: 0.9262\nEpoch 27/31\n253/253 [==============================] - 298s 1s/step - loss: 0.0293 - accuracy: 0.9903 - val_loss: 0.1959 - val_accuracy: 0.9366\nEpoch 28/31\n253/253 [==============================] - 296s 1s/step - loss: 0.0313 - accuracy: 0.9890 - val_loss: 0.0713 - val_accuracy: 0.9718\nEpoch 29/31\n253/253 [==============================] - 297s 1s/step - loss: 0.0330 - accuracy: 0.9891 - val_loss: 0.1663 - val_accuracy: 0.9485\nEpoch 30/31\n253/253 [==============================] - 318s 1s/step - loss: 0.0232 - accuracy: 0.9915 - val_loss: 0.1535 - val_accuracy: 0.9510\nEpoch 31/31\n253/253 [==============================] - 295s 1s/step - loss: 0.0294 - accuracy: 0.9905 - val_loss: 0.1924 - val_accuracy: 0.9376\n64/64 [==============================] - 59s 904ms/step\nFold 3:\nClassification Report:\n                      precision    recall  f1-score   support\n\n Bacterial Pneumonia       0.93      0.99      0.96       402\nCorona Virus Disease       0.99      1.00      0.99       406\n              Normal       1.00      0.96      0.98       402\n        Tuberculosis       1.00      0.99      0.99       407\n     Viral Pneumonia       0.98      0.95      0.96       402\n\n            accuracy                           0.98      2019\n           macro avg       0.98      0.98      0.98      2019\n        weighted avg       0.98      0.98      0.98      2019\n\nConfusion Matrix:\n[[398   1   0   0   3]\n [  0 406   0   0   0]\n [ 10   0 385   1   6]\n [  0   5   0 402   0]\n [ 18   0   1   0 383]]\n################# Results for fold:- 4 ###################\nFound 8076 validated image filenames belonging to 5 classes.\nFound 2019 validated image filenames belonging to 5 classes.\nEpoch 1/31\n253/253 [==============================] - 296s 1s/step - loss: 0.0503 - accuracy: 0.9837 - val_loss: 0.0426 - val_accuracy: 0.9866\nEpoch 2/31\n253/253 [==============================] - 293s 1s/step - loss: 0.0468 - accuracy: 0.9837 - val_loss: 0.1786 - val_accuracy: 0.9470\nEpoch 3/31\n253/253 [==============================] - 295s 1s/step - loss: 0.0335 - accuracy: 0.9902 - val_loss: 0.2605 - val_accuracy: 0.9227\nEpoch 4/31\n253/253 [==============================] - 290s 1s/step - loss: 0.0404 - accuracy: 0.9868 - val_loss: 0.0881 - val_accuracy: 0.9728\nEpoch 5/31\n253/253 [==============================] - 293s 1s/step - loss: 0.0392 - accuracy: 0.9861 - val_loss: 0.0392 - val_accuracy: 0.9856\nEpoch 6/31\n253/253 [==============================] - 289s 1s/step - loss: 0.0295 - accuracy: 0.9892 - val_loss: 0.0829 - val_accuracy: 0.9713\nEpoch 7/31\n253/253 [==============================] - 294s 1s/step - loss: 0.0286 - accuracy: 0.9908 - val_loss: 0.1439 - val_accuracy: 0.9574\nEpoch 8/31\n253/253 [==============================] - 290s 1s/step - loss: 0.0342 - accuracy: 0.9877 - val_loss: 0.0496 - val_accuracy: 0.9802\nEpoch 9/31\n253/253 [==============================] - 294s 1s/step - loss: 0.0220 - accuracy: 0.9929 - val_loss: 0.0495 - val_accuracy: 0.9827\nEpoch 10/31\n253/253 [==============================] - 292s 1s/step - loss: 0.0367 - accuracy: 0.9866 - val_loss: 0.0355 - val_accuracy: 0.9871\nEpoch 11/31\n253/253 [==============================] - 293s 1s/step - loss: 0.0322 - accuracy: 0.9890 - val_loss: 0.0573 - val_accuracy: 0.9802\nEpoch 12/31\n253/253 [==============================] - 291s 1s/step - loss: 0.0270 - accuracy: 0.9911 - val_loss: 0.1091 - val_accuracy: 0.9624\nEpoch 13/31\n253/253 [==============================] - 293s 1s/step - loss: 0.0225 - accuracy: 0.9918 - val_loss: 0.4420 - val_accuracy: 0.9034\nEpoch 14/31\n253/253 [==============================] - 292s 1s/step - loss: 0.0311 - accuracy: 0.9903 - val_loss: 0.2322 - val_accuracy: 0.9242\nEpoch 15/31\n253/253 [==============================] - 297s 1s/step - loss: 0.0338 - accuracy: 0.9871 - val_loss: 0.0751 - val_accuracy: 0.9728\nEpoch 16/31\n253/253 [==============================] - 291s 1s/step - loss: 0.0235 - accuracy: 0.9924 - val_loss: 0.1140 - val_accuracy: 0.9604\nEpoch 17/31\n253/253 [==============================] - 294s 1s/step - loss: 0.0335 - accuracy: 0.9894 - val_loss: 0.0822 - val_accuracy: 0.9708\nEpoch 18/31\n253/253 [==============================] - 291s 1s/step - loss: 0.0277 - accuracy: 0.9908 - val_loss: 0.1243 - val_accuracy: 0.9609\nEpoch 19/31\n253/253 [==============================] - 296s 1s/step - loss: 0.0186 - accuracy: 0.9934 - val_loss: 0.1874 - val_accuracy: 0.9465\nEpoch 20/31\n253/253 [==============================] - 292s 1s/step - loss: 0.0262 - accuracy: 0.9918 - val_loss: 0.0761 - val_accuracy: 0.9713\nEpoch 21/31\n253/253 [==============================] - 299s 1s/step - loss: 0.0287 - accuracy: 0.9905 - val_loss: 0.1241 - val_accuracy: 0.9579\nEpoch 22/31\n253/253 [==============================] - 294s 1s/step - loss: 0.0172 - accuracy: 0.9943 - val_loss: 0.3011 - val_accuracy: 0.9198\nEpoch 23/31\n253/253 [==============================] - 299s 1s/step - loss: 0.0304 - accuracy: 0.9901 - val_loss: 0.1084 - val_accuracy: 0.9619\nEpoch 24/31\n253/253 [==============================] - 296s 1s/step - loss: 0.0347 - accuracy: 0.9881 - val_loss: 0.0746 - val_accuracy: 0.9757\nEpoch 25/31\n253/253 [==============================] - 301s 1s/step - loss: 0.0248 - accuracy: 0.9923 - val_loss: 0.2381 - val_accuracy: 0.9316\nEpoch 26/31\n253/253 [==============================] - 297s 1s/step - loss: 0.0291 - accuracy: 0.9908 - val_loss: 0.1329 - val_accuracy: 0.9579\nEpoch 27/31\n253/253 [==============================] - 295s 1s/step - loss: 0.0249 - accuracy: 0.9906 - val_loss: 0.1236 - val_accuracy: 0.9683\nEpoch 28/31\n253/253 [==============================] - 293s 1s/step - loss: 0.0212 - accuracy: 0.9923 - val_loss: 0.1245 - val_accuracy: 0.9594\nEpoch 29/31\n253/253 [==============================] - 292s 1s/step - loss: 0.0210 - accuracy: 0.9933 - val_loss: 0.2129 - val_accuracy: 0.9445\nEpoch 30/31\n253/253 [==============================] - 291s 1s/step - loss: 0.0207 - accuracy: 0.9934 - val_loss: 0.2488 - val_accuracy: 0.9331\nEpoch 31/31\n253/253 [==============================] - 291s 1s/step - loss: 0.0291 - accuracy: 0.9917 - val_loss: 0.0836 - val_accuracy: 0.9733\n64/64 [==============================] - 58s 900ms/step\nFold 4:\nClassification Report:\n                      precision    recall  f1-score   support\n\n Bacterial Pneumonia       0.99      0.96      0.97       401\nCorona Virus Disease       0.99      1.00      0.99       407\n              Normal       0.99      1.00      0.99       402\n        Tuberculosis       1.00      1.00      1.00       407\n     Viral Pneumonia       0.97      0.98      0.97       402\n\n            accuracy                           0.99      2019\n           macro avg       0.99      0.99      0.99      2019\n        weighted avg       0.99      0.99      0.99      2019\n\nConfusion Matrix:\n[[385   2   0   0  14]\n [  0 407   0   0   0]\n [  0   1 401   0   0]\n [  0   1   0 406   0]\n [  5   1   4   0 392]]\n################# Results for fold:- 5 ###################\nFound 8076 validated image filenames belonging to 5 classes.\nFound 2019 validated image filenames belonging to 5 classes.\nEpoch 1/31\n253/253 [==============================] - 294s 1s/step - loss: 0.0324 - accuracy: 0.9894 - val_loss: 0.3087 - val_accuracy: 0.9138\nEpoch 2/31\n253/253 [==============================] - 295s 1s/step - loss: 0.0307 - accuracy: 0.9900 - val_loss: 0.0337 - val_accuracy: 0.9861\nEpoch 3/31\n253/253 [==============================] - 292s 1s/step - loss: 0.0207 - accuracy: 0.9932 - val_loss: 0.1865 - val_accuracy: 0.9534\nEpoch 5/31\n253/253 [==============================] - 291s 1s/step - loss: 0.0322 - accuracy: 0.9896 - val_loss: 0.0770 - val_accuracy: 0.9737\nEpoch 6/31\n253/253 [==============================] - 293s 1s/step - loss: 0.0248 - accuracy: 0.9923 - val_loss: 0.0675 - val_accuracy: 0.9802\nEpoch 7/31\n253/253 [==============================] - 296s 1s/step - loss: 0.0297 - accuracy: 0.9889 - val_loss: 0.0325 - val_accuracy: 0.9891\nEpoch 8/31\n253/253 [==============================] - 290s 1s/step - loss: 0.0216 - accuracy: 0.9933 - val_loss: 0.0645 - val_accuracy: 0.9797\nEpoch 9/31\n253/253 [==============================] - 293s 1s/step - loss: 0.0268 - accuracy: 0.9907 - val_loss: 0.0529 - val_accuracy: 0.9827\nEpoch 10/31\n253/253 [==============================] - 291s 1s/step - loss: 0.0228 - accuracy: 0.9927 - val_loss: 0.0492 - val_accuracy: 0.9842\nEpoch 11/31\n253/253 [==============================] - 293s 1s/step - loss: 0.0193 - accuracy: 0.9922 - val_loss: 0.0753 - val_accuracy: 0.9762\nEpoch 12/31\n253/253 [==============================] - 292s 1s/step - loss: 0.0254 - accuracy: 0.9920 - val_loss: 0.0483 - val_accuracy: 0.9827\nEpoch 13/31\n253/253 [==============================] - 293s 1s/step - loss: 0.0255 - accuracy: 0.9915 - val_loss: 0.0555 - val_accuracy: 0.9827\nEpoch 14/31\n253/253 [==============================] - 292s 1s/step - loss: 0.0271 - accuracy: 0.9920 - val_loss: 0.0411 - val_accuracy: 0.9851\nEpoch 15/31\n253/253 [==============================] - 294s 1s/step - loss: 0.0145 - accuracy: 0.9943 - val_loss: 0.0474 - val_accuracy: 0.9851\nEpoch 16/31\n253/253 [==============================] - 292s 1s/step - loss: 0.0281 - accuracy: 0.9911 - val_loss: 0.0850 - val_accuracy: 0.9673\nEpoch 17/31\n253/253 [==============================] - 294s 1s/step - loss: 0.0216 - accuracy: 0.9921 - val_loss: 0.0825 - val_accuracy: 0.9703\nEpoch 18/31\n253/253 [==============================] - 293s 1s/step - loss: 0.0190 - accuracy: 0.9936 - val_loss: 0.0307 - val_accuracy: 0.9886\nEpoch 19/31\n253/253 [==============================] - 295s 1s/step - loss: 0.0201 - accuracy: 0.9936 - val_loss: 0.4555 - val_accuracy: 0.9009\nEpoch 20/31\n253/253 [==============================] - 292s 1s/step - loss: 0.0243 - accuracy: 0.9915 - val_loss: 0.0658 - val_accuracy: 0.9777\nEpoch 21/31\n122/253 [=============>................] - ETA: 2:01 - loss: 0.0213 - accuracy: 0.9933","output_type":"stream"}]}]}